# Configuration file for particle swarm optimization
# lines containing "#" are comments
# only a single value can be set in each line
# This configuration file is structured in five sections:
#  - Objective function specification
#  - Swarm parameters and swarm configuration
#  - Precision configuration
#  - Specification which statistics are written to data files
#  - Miscellaneous options
#
# As this is the complete set of options this file is quite big and can be
# confusing. We recommend to use the online tool for configuration file
# generation. For this purpose use the following link:
# https://www12.informatik.uni-erlangen.de/downloads/eako/HiPPSOconfigurationFileGeneration/index.php

##############################################################
########       OBJECTIVE FUNCTION SPECIFICATION       ########
##############################################################

# Set the number of dimensions of the search space.
dimensions 8


# The option function specifies the objective function which has to be
# minimized by the PSO. A <function type> is some specification of an
# evaluation which can be executed on a position vector and produces a single
# result value.

function standard sphere
#function <function type>

# The type of function (<function type>) should be specified
# as described with the following grammar, which is specified
# in Backus-Naur Form:

# <function type>                 ::= <direct function type> | <operation> <function type> |
#                                     <reduce operator> <specific function type> |
#                                     combine <combination> <function type> <function type>
# <direct function type>          ::= standard <standard function> | constant <constant value>
# <standard function>             ::= sphere | scaledsphere | scaledsphere2 <scale> |
#                                     scaledsphererand <rng description> | scaledandhadamardrotatedshpere |
#                                     scaledandhadamardrotatedshpere2 <scale> | monosphere | schwefel |
#                                     schwefel2 | rosenbrock | movedrosenbrock | rastrigin |
#                                     randomposdef <rng description> | diagonal <scale> | norm1 | normoo |
#                                     norm2 | norm4 | norm8 | norm2pk <positive int exponent> |
#                                     norm1pl2pmk <positive int exponent> | sphereplus | inclinedplane | inclinedplaneasym |
#                                     twoCupsFunction | sortFunction |
#                                     singleDifferentDirection <single dimension power> <remaining dimension power> <direction_mode> |
#                                     testing
# <direction_mode>                ::= firstDimension | diagonalDirection | randomDirection <rng description>
# <operation>                     ::= sqrt | log2 | logE | abs | pow <float exponent> | exp |
#                                     sin | cos | tan | arcsin | arccos | arctan
# <specific function type>        ::= <direct specific function type> | <operation> <specific function type> |
#                                     combine <combination> <specific function type> <specific function type>
# <direct specific function type> ::= identity | constant <constant value>
# <reduce operator>               ::= reduce <reduce type>
# <reduce type>                   ::= specific <element id> | increasingOrderNthObject <element id> | arithmeticAverage |
#                                     geometricAverage | sum | product | maximum | minimum | functionEvaluation <function type>
# <constant value>                ::= E | Pi | plusInfinity | minusInfinity | <floating point number>
# <float exponent>                      ::= <floating point number>
# <combination>                   ::= + | - | * | / | min | max
# <element id>                    ::= <nonnegative integer>
# <scale>                         ::= <floating point number>
# <positive int exponent>         ::= <positive integer>
# <single dimension power>        ::= <floating point number>
# <remaining dimension power>     ::= <floating point number>
# <rng description>  See section about random number generator ("srand")!

# <function type>
#  A <function type> is some specification of an evaluation which can be
#  executed on a position vector and produces a single result value.

# <direct function type>
#  A <direct function type> describes a specific function directly. The
#  solution vectors are evaluated to single values. Examples are standard
#  functions (Sphere, Rastrigin, Rosenbrock, etc.) or constant functions.

# <standard function>
#  This option offers the chance to use a variety of pre implemented functions
#  (Sphere, Rastrigin, Rosenbrock, etc.).
# sphere
#  "sphere" is the well know sphere function Sphere(x) = sum ((x[i])^2).
# scaledsphere
#  "scaledsphere" is a scaled version of the Sphere function:
#  scaledsphere(x) = sum ((10^6)^(i/(D-1))(x[i]^2)).
# scaledsphere2 <scale>
#  "scaledsphere2 <scale>" is the same but the user can specify the scale as
#  floating point number:
#  scaledsphere2 <scale> (x) = sum ((<scale>)^(i/(D-1))(x[i]^2)).
# scaledsphererand <rng description>
#  "scaledsphererand <rng description>" is a randomized version with randomly
#  generated scales per dimension:
#  scaledsphererand <rng description> (x) =
#   = sum (r_i(x[i]^2))
#   where r_i are once randomly generated non negative integer numbers with
#   given RNG.
# scaledandhadamardrotatedshpere
#  If the number of dimensions D = 2^d is a power of two then
#  "scaledandhadamardrotatedshpere" is a "scaledsphere" with Hadamard rotated
#  input x.
# scaledandhadamardrotatedshpere2 <scale>
#  "scaledandhadamardrotatedshpere2 <scale>" is analogously to
#  "scaledandhadamardrotatedshpere" but with user defined scale as floating
#  point number.
# monosphere
#  monosphere (x) = (x[0])^2.
# schwefel
#  schwefel (x) = sum_{i=0..D-1} ((sum_{j=0..i} x[j])^2).
# schwefel2
#  "schwefel2" is also known as Schwefel function in the literature.
#  schwefel2 (x) = sum_{i=0..D-1} (-x[i] * sin(sqrt(abs(x[i])))).
# rosenbrock
#  rosenbrock (x) = sum{i=0..D-2} (100 * (x[i+1] - x[i] * x[i])^2 + (1 - x[i])^2).
# movedrosenbrock
#  "movedrosenbrock" is a moved version of the rosenbrock function such that
#  the optimum is at the origin.
#  movedrosenbrock (x) =rosenbrock([(x[0])+1,(x[1])+1,....]).
# rastrigin
#  rastrigin (x) = sum{i=0..D-1} (10 + x[i]^2 - 10 * cos(2 * PI * x[i])).
# randomposdef <rng description>
#  randomposdef <rng description> (x) = Transpose(x) * A * x
#  with a once randomly generated positive definite matrix A with given RNG.
# diagonal <scale>
#  diagonal <scale> (x) = (sphere (x)) + <scale> * (sum(x[i]))^2.
# norm1
#  "norm1" is the Manhattan norm. norm1 (x) = sum abs(x[i]).
# normoo
#  "normoo" is the infinity norm. normoo (x) = max abs(x[i]).
# norm2
#  "norm2" is equivalent to the Sphere function.
# norm4
#  norm4 (x) = sum ((x[i])^4).
# norm8
#  norm8 (x) = sum ((x[i])^8).
# norm2pk <positive int exponent>
#  "norm2pk <positive int exponent>" is equivalent to the
#  2^<positive int exponent> norm.
#  norm2pk <positive int exponent> (x) =
#   = sum ((x[i])^(2^<positive int exponent>)).
# norm1pl2pmk <positive int exponent>
#  "norm1pl2pmk <positive int exponent>" is equivalent to the
#  (1+2^(-<positive int exponent>)) norm.
#  norm1pl2pmk <positive int exponent> (x) =
#   = sum ((abs(x[i]))^(1+2^(-<positive int exponent>))).
# sphereplus
#  sphereplus (x) = (sphere (x)) if every entry of x is non-negative,
#  and INFINITY otherwise.
# inclinedplane
#  inclinedplane (x) = -sum_{i=0..D-1} x[i].
# inclinedplaneasym
#  inclinedplaneasym (x) = -sum_{i=0..D-1} (i+1)*x[d].
# twoCupsFunction
#  twoCupsFunction (x) = sum_{i=0..D-1} f(x[i]),
#  where f(y) = (y+1)^2 if y <  0 and f(y) = (y-1)^4 if y >= 0.
# sortFunction
#  sortFunction (x) = sum_{0<=d_1<d_2<D} (x[d_1]>=x[d_2])
# singleDifferentDirection <single dimension power> <remaining dimension power> <direction mode>
#  Let "dir" be the specified direction specified by the <direction mode> then
#  singleDifferentDirection (x) is evaluated by the following sequence of
#  instructions:
#     proj := ((x.dir)/(dir.dir)) * dir;
#     // proj is the projection of the current position to dir
#     orth := x - proj;
#     // orth is the orthogonal part of the position
#     return (proj.proj)^<single dimension power> + (orth.orth)^<remaining dimension power>;
#     // Here (a.b) is the scalar product of the vectors a and b.
# testing
#  This function is just for testing and debugging. Behavior and shape is not
#  defined and may change during the process or after software updates.

# <direction mode> = firstDimension: if "<direction mode>" is set to
#  "firstDimension" then the special direction is dir=(1,0,...,0)
# <direction mode> = diagonalDirection: if "<direction mode>" is set to
#  "diagonalDirection" then the special direction is dir=(1,1,...,1)
# <direction mode> = randomdirection <rng description>:
#  if "<direction mode>" is set to "randomdirection <rng description>"
#  then the special direction is dir=(y[0],...,y[D-1]), where each y[i]
#  is an independent normal distributed random variable with expectation
#  0 and variance 1 generated with the given RNG and its random double values.
#  Examples:
#    function standard singleDifferentDirection 4 1 firstDimension
#    function standard singleDifferentDirection 1 4 diagonalDirection
#    function standard singleDifferentDirection 0.5 12.25 randomDirection 4242

# constant <constant value>
#  "constant <constant value>" represents a function, which always evaluates to
#  the same specified value.
# <constant value> = E
#  If "<constant value>" is set to "E" then we have Euler's number. It is
#  approximately 2.71828. This value is always evaluated according to the
#  current precision.
# <constant value> = Pi
#  If "<constant value>" is set to "Pi" then we have The number Pi. It is
#  approximately 3.14159. This value is always evaluated according to the
#  current precision.

# <operation> <function type>
# <operation> <specific function type>
# An <operation> is applied to the result delivered by the connected
# <function type>/<specific function type> object. Examples for operations are
# the logarithm, the square root or trigonometric functions.
# <operation> = sqrt:
#  "sqrt" is the square root.
#   WARNING: executions with negative values result in undefined values.
# <operation> = log2:
#  "log2" is the logarithm with base 2.
#   WARNING: executions with negative values result in undefined values.
# <operation> = logE:
#  "logE" is the natural logarithm (logarithm with base E).
#   WARNING: executions with negative values result in undefined values.
# <operation> = abs:
#  "abs" is the absolute value.
# <operation> = pow <float exponent>:
#  "pow <float exponent>" is the power of the value with the specified
#  exponent.
#   WARNING: executions with negative values (can) result in undefined values.
# <operation> = exp:
#  "exp" is the exponential function.
# <operation> = sin:
#  "sin" is the sine function.
# <operation> = cos:
#  "cos" is the cosine function.
# <operation> = tan:
#  "tan" is the tangent function.
# <operation> = arcsin:
#  "arcsin" is the respective arcus-functions to the sine function
#  (inverse trigonometric function)
# <operation> = arccos:
#  "arccos" is the respective arcus-functions to the cosine function
#  (inverse trigonometric function)
# <operation> = arctan:
#  "arctan" is the respective arcus-functions to the tangent function
#  (inverse trigonometric function)

# The combine commands:
#  combine <combination> <function type> <function type>
#  combine <combination> <specific function type> <specific function type>
#   The combine commands "combine <combination> <function type> <function type>"
#   and "combine <combination> <specific function type> <specific function type>"
#   can be used to evaluate complex functions. You can use add (+),
#   subtract (-), multiply (*), divide (/), minimum (min) and maximum (max) as
#   possible combinations to combine various functions. Each combination is
#   executed element wise. The option is described by a prefix notation for the
#   evaluation which uniquely specifies the order of execution.
#   WARNING: Undefined values can not be compared (e.g. for minimum). Undefined
#   values can appear for example if there is a division by zero.

# <function type> = reduce <reduce type> <specific function type>
#  The reduce operator reduces the data vector received from some specific
#  function to a single number. Some kind of aggregation can be done, e.g.,
#  sums or products. A <specific function type> calculates a vector of values
#  by the given solution vector.

# <reduce type>
#  The reduce operator specifies how values are combined.
# <reduce type> = specific <element id>
#  "specific <element id>" picks only the value at some specified index. Please
#  note that the indices are 0-indexed.
#   Example for <function type>:
#    Let the position of the current particle be (7,6,5) then the
#    following functions can be applied:
#    "reduce specific 0 identity" produces the data 7,
#    "reduce specific 1 identity" produces the data 6 and
#    "reduce specific 2 identity" produces the data 5.
# <reduce type> = increasingOrderNthObject <element id>
#  "increasingOrderNthObject <element id>" picks the value at the specified
#  position after the values, which should be reduced, are sorted. Please note
#  that the indices are 0-indexed.
#   Example:
#    Let the position of the current particle be (7,6,5) then the
#    following functions can be applied:
#    "reduce increasingOrderNthObject 0 identity" produces the data 5,
#    "reduce increasingOrderNthObject 1 identity" produces the data 6 and
#    "reduce increasingOrderNthObject 2 identity" produces the data 7.
# <reduce type> = arithmeticAverage
#  "arithmeticAverage" calculates the arithmetic average of the values which
#  should be reduced.
#   Example:
#    Let the position of the current particle be (7,6,5) then the
#    following function can be applied:
#    "reduce arithmeticAverage identity" produces the data 6.
# <reduce type> = geometricAverage
#  "geometricAverage" calculates the geometric average of the values which
#  should be reduced.
#   Example:
#    Let the position of the current particle be (6,4,9) then the
#    following function can be applied:
#    "reduce geometricAverage identity" produces the data 6.
# <reduce type> = sum
#  "sum" caculates the sum of the values which should be reduced.
#   Example:
#    Let the position of the current particle be (6,4,9) then the
#    following function can be applied:
#    "reduce sum identity" produces the data 19.
# <reduce type> = product
#  "product" calculates the product of the values which should be reduced.
# <reduce type> = maximum
#  "maximum" calculates the maximal value of the values which should be reduced.
# <reduce type> = minimum
#  "minimum" calculates the minimal value of the values which should be reduced.
# <reduce type> = functionEvaluation <function type>
#  "functionEvaluation <function type>" interprets the values which should be
#  reduced as input of the specified function and evaluates this function.

# <specific function type>
#  A "<specific function type>" represents a vector of values, which is
#  calculated with the given position. It needs to be reduced in some way to
#  receive an usable function, which can then be evaluated.
# <direct specific function type>
#  A "<direct specific function type>" describes a specific
#  "<specific function type>" directly.

# <direct specific function type> = identity
#  "identity" supplies the bare position/input which should be evaluated as
#  output.
# <direct specific function type> = constant <constant value>
#  "constant <constant value>" represents a function, which always evaluates to
#  the same specified value. The number of dimensions of the result will be
#  equal to the number of dimensions of the search space.

# Further examples for functions:
#  sphere function (two variants)
#function standard sphere
#function reduce sum pow 2 identity
#  function <k>-Norm:
#function reduce sum pow <k> abs identity
#function reduce sum pow 17 abs identity
#  monosphere (two variants)
#function standard monosphere
#function pow 2 reduce specific 0 identity
#  diagonal 1000 function (two variants)
#function standard diagonal 1000
#function combine + reduce sum pow 2 identity combine * constant 1000 pow 2 reduce sum identity
#  moved rosenbrock function such that origin is optimum (two variants)
#  WARNING: Second variant does not preserve standard function bounds of rosenbrock function.
#           Use functionbounds command to set them manually.
#function standard movedrosenbrock
#function reduce functionEvaluation standard rosenbrock combine + identity constant 1

# functionbounds <first dimension id> <last dimension id> <lower bound> <upper bound>
#  Sets the lower and upper bound of the bounding box for the function to the
#  given values for all dimensions form <first dimension id> to
#  <last dimension id>. Relevant for initialization of the particles (if
#  "initializationinformation" with subcommands "bounds", "centerandrange" and
#  "randomcenterandrange" is not used) and it is relevant for bound handling
#  and for the option "functionInfinityOutside". For standard functions the
#  usual function bounds are implemented, but for all other functions or
#  functions consisting of more than just a standard function the function
#  bounds are set to [-100.0, 100.0] in all dimensions. If any other function
#  bound is intended, then it need to be specified! Please note that dimension
#  indices are 0-indexed and the ranges are inclusive bounds.

##############################################################
########   SWARM PARAMETERS AND SWARM CONFIGURATION   ########
##############################################################

# Set the number of particles.
particles 8

# Set the number of steps (iterations).
steps 1000

# Set parameters for velocity update in PSO.
# v[i] = (chi) * v[i] + c_{loc} * r_1 * (l[i] - x[i]) + c_{glob} * r_2 * (g[i] - x[i])
# for each dimension i separately,
# where v = velocity,
# c_{loc} = coefficient local attractor,
# c_{glob} = coefficient global attractor,
# r_1 and r_2 random values in [0,1],
# l = local attractor,
# x = position,
# g global attractor.
# A standard combination of parameters is chi=0.72984, c_{loc}=c_{glob}=1.496172.
parameterChi 0.72984
parameterCoefficientLocalAttractor 1.496172
parameterCoefficientGlobalAttractor 1.496172

# Set how the velocity of each particle should be initialized.
initializeVelocity zero
#initializeVelocity < zero | halfDiff | random >
# initializeVelocity zero
#  This option initializes all velocity entries to zero.
# initializeVelocity halfDiff
#  This option samples a second position for each particle, subtracts the
#  actual position and multiplies the result by 0.5.
# initializeVelocity random
#  Velocities are initialized similar to the position.
#  See command initializationinformation in this case.

# Set how positions and velocities are initialized
#initializationinformation <position or velocity> <affected particles and dimensions> <initialization type>
# with
# <position or velocity>              ::= position | velocity
# <affected particles and dimensions> ::= <first particle id> <last particle id> <first dimension id> <last dimension id>
# <initialization type>               ::= bounds <lower bound> <upper bound> |
#                                         centerandrange <center coordinate> <range> |
#                                         randomcenterandrange <center coordinate lower bound> <center coordinate upper bound> <range> |
#                                         scale <scale> |
#                                         powerscale <power scale>
# <first particle id>                 ::= <nonnegative integer>
# <last particle id>                  ::= <nonnegative integer>
# <first dimension id>                ::= <nonnegative integer>
# <last dimension id>                 ::= <nonnegative integer>
# <lower bound>                       ::= <floating point number>
# <upper bound>                       ::= <floating point number>
# <center coordinate>                 ::= <floating point number>
# <range>                             ::= <floating point number>
# <center coordinate lower bound>     ::= <floating point number>
# <center coordinate upper bound>     ::= <floating point number>
# <scale>                             ::= <floating point number>
# <power scale>                       ::= <integer value>

#Detailed information about the command "initializationinformation":

# Please note:
# The commands which influences the velocity initialization are ignored if
# velocity initialization is not random. For example if the command
# "initializeVelocity halfDiff" or "initializeVelocity zero" is active then the
# command "initializationinformation" with subcommand "velocity" has no effect.
# Particles and dimensions are 0-indexed, the ids of the particles are in the
# range from 0 to one less than the respective number. Particle and dimension
# ranges are inclusive their bounds.

# <position or velocity>
#  This option specifies whether the command influences the initialization of
#  the position or the velocity.
# <affected particles and dimensions>
#  This option specifies which particles and which dimensions are affected. The
#  specified indices should be integers. The indices are treated zero indexed
#  and inclusive specified index bounds.

# <initialization type> = bounds <lower bound> <upper bound>
#  This option specifies that the coordinates of all particles and dimensions
#  in the specified range are randomly initialized in the range from
#  <lower bound> to <upper bound>. <lower bound> and <upper bound> can be
#  floating point values.
#
# <initialization type> = centerandrange <center coordinate> <range>
#  This option specifies that the coordinates of all particles and dimensions
#  in the specified range are randomly initialized in the interval from
#  (<center coordinate> - <range>) to (<center coordinate> + <range>).
#  <center coordinate> and <range> can be floating point values.
#
# <initialization type> = randomcenterandrange <center coordinate lower bound> <center coordinate upper bound> <range>
#  This option specifies that the coordinates of all particles and dimensions
#  in the specified range are randomly initialized in the interval from
#  (x - <range>) to (x + <range>), where x is a random value in the interval
#  <lower bound> to <upper bound> and x is sampled for each dimension
#  independently.
#
# <initialization type> = scale <scale>
#  This option specifies that the length of the random interval of all
#  particles and dimensions in the specified range are scaled by a factor of
#  <scale>. The center of the interval stays constant. <scale> can be a
#  floating point value.
#
# <initialization type> = powerscale <power scale>
#  This option specifies that the length of the random interval of all
#  particles and dimensions in the specified range are scaled by a factor of
#  2^(<power scale>). The center of the interval stays constant. <power scale>
#  needs to be an integer (negative or positive).

# The subcommands "bounds", "centerandrange" and "randomcenterandrange" are
# procceded in the same order as they are inserted in the configuration file.
# Therefore such commands can overwrite previous commands of these three
# types if they have an effect on the same particles and dimensions.
# For example if subcommand "centerandrange" on particles 0 to 4 and
# dimensions 4 to 7 is stated and the subcommand "bounds" on particles
# 3 to 5 and dimensions 2 to 5, then for the overlap (particles 2 to 4
# and dimensions 4 to 5) the later subcommand "bounds" is in effect. For
# the remaining particles and dimensions the subcommands "centerandrange"
# and "bounds" are in effect as specified.
# The remaining subcommands "scale" and "powerscale" can coexist. This means
# if two (or more) of those commands appear for the same particle and dimension
# then all of them will be executed.
# Furthermore the subcommands "scale" and "powerscale" are executed after
# all subcommands "bounds", "centerandrange" and "randomcenterandrange"
# are finished. Therefore a different ordering of the subcommands "scale" and
# "powerscale" has no effect.

# For all particles and dimensions where no range is specified the function bounds
# are used. For position sampling there is just random sampling inside the function bounds.
# For velocity sampling inside function bounds (not for initialization with command
# initializationinformation) additionally the center of the function bounds is subtracted
# to ensure that for each dimension positive and negative direction has equal probability.

# Set neighborhood topology.
neighborhood gBest
#neighborhood < gBest | wheel | lBest <2 times k> | ring | grid <number of rows> <number of columns> >
# <2 times k>         ::= <positive integer value>
# <number of rows>    ::= <positive integer value>
# <number of columns> ::= <positive integer value>
# This option sets the neighborhood topology. The neighborhood topology
# specifies which particles are known by other particles, i.e., if particle i
# knows particle j then the best position found by particle j is considered for
# the choice of global attractor for particle i.

# neighborhood gBest
#  All particles know each other. There is a single common global attractor for
#  all particles.
# neighborhood wheel
#  All particles know the first particle and the first particle knows all
#  particles. The global attractor of the first particle is the best position
#  of all particles. The global attractor of all other particles is the best
#  position of itself and the best position of the first particle.
# neighborhood lBest <2 times k>
#  Each particle knows the next and the previous <2 times k> / 2 particles. For
#  example "neighborhood lBest 10" specifies that each particle knows the next
#  and the previous 5 particles.
# neighborhood ring
#  Each particle knows the next and the previous particle.
#  (equivalent to "lBest 2")
# neighborhood grid <number of rows> <number of columns>
#  The particles are assigned a position in a <number of rows> times
#  <number of columns> grid. Each particle knows the four particles next to
#  him, i.e., the particle above, below, left and right to him in a cyclical
#  sense. Please note: <number of rows> multiplied by <number of columns> must
#  be equal to the number of particles!
#  (for example if there are 36 particles then one option is: "neighborhood grid 4 9")

# Set position and velocity update strategy.
positionAndVelocityUpdater default
#positionAndVelocityUpdater < default | orientationChange <delta> | delta <delta> | delta <delta> <gamma> | deltatcs <delta> | deltatcs <delta> <gamma> | dimensionindependent <reduction scale> <max directions> | testing >
# <delta>           ::= <floating point number>
# <gamma>           ::= <floating point number>
# <reduction scale> ::= <floating point number>
# <max directions>  ::= <nonnegative integer value>
#
# positionAndVelocityUpdater default
#  "positionAndVelocityUpdater default" means just that the well known movement
#  equations are used in their standard form.
#
# positionAndVelocityUpdater orientationChange <delta>
#  "positionAndVelocityUpdater orientationChange <delta>" means the following:
#  Random values of the standard movement equations are calculated in an
#  orthogonal transformed space.
#  Let p[i] = log_2 (abs(v[i]) + abs(x[i] - l[i]) + abs(x[i] - g[i])),
#  where x[i], v[i], l[i] and g[i] are the position, velocity, local attractor
#  and global attractor of "direction" i at the current iteration and particle.
#  If in current orientation the minimal and maximal value of p[i] differ more
#  than "<delta>" then the lowest and largest directions are rotated with a
#  hadamard transformation. Beside that change the default behaviour is used.
#
# positionAndVelocityUpdater delta <delta>
#  "positionAndVelocityUpdater delta <delta>" means that if for a particle and
#  all dimensions (abs(x[i]-g[i]) + abs(v[i])) < (<delta>) then the velocity is
#  initialized randomly in [-<delta>, <delta>] for all dimensions. Otherwise
#  default behavior is used. This variant is described in the paper "Particle
#  Swarm Optimization Almost Surely Finds Local Optima" by M. Schmitt and R.
#  Wanka published in Proceedings of GECCO 2013.
#
# positionAndVelocityUpdater delta <delta> <gamma>
#  "positionAndVelocityUpdater delta <delta> <gamma>" means the same but with
#  limit and scale <delta>*(<gamma>^k) where k is the number of times the
#  random initialization of the velocity is applied already. If <gamma> equals
#  1.0 then this updater performs equal to the updater with only one parameter.
#
# positionAndVelocityUpdater deltatcs <delta>
#  "positionAndVelocityUpdater deltatcs <delta>" means that if in the situation
#  of an update for position and velocity for a particle p the new velocity is
#  initialized randomly in [-<delta>, <delta>] in those dimensions, where for
#  ALL particles the following condition is true in that dimension:
#  (abs(x[i]-g[i]) + abs(v[i])) < (<delta>). For all other dimensions default
#  behavior is used. This variant is described in the paper "Particle Swarm
#  Optimization Almost Surely Finds Local Optima" by M. Schmitt and R. Wanka
#  published in Journal TCS 2014.
#
# positionAndVelocityUpdater deltatcs <delta> <gamma>
#  "positionAndVelocityUpdater deltatcs <delta> <gamma>" means the same but
#  with limit and scale <delta>*(<gamma>^k) where k is the number of times the
#  random initialization of the velocity is applied already. If <gamma> equals
#  1.0 then this updater performs equal to the updater with only one parameter.
#
# positionAndVelocityUpdater dimensionindependent <reduction scale> <max directions>
#  "positionAndVelocityUpdater dimensionindependent <reduction> <max_directions>"
#  means that for each update is performed in at most <max_directions>
#  directions. Each update direction is calculated orthogonally to the previous
#  directions and is performed in main movement direction plus some random
#  direction scaled by <reduction>. The smaller the value of <reduction> is the
#  greater is the portion of the main movement direction belonging to the first
#  sampled direction.
#  Formally:
#  First the previous velocity is scaled by the specified swarm parameter;
#  main movement direction =
#  (difference vector of local and global attractor) if they are not equal and
#  (difference vector of position and any of the equal attractors) otherwise.
#  If this vector is a zero vector then position and attractors are equal and
#  therefore there is no vector to local/global attractor, which can be scaled randomly.
#  The directions are sampled iteratively:
#  used_directions := {};
#  for d from 1 to <max_directions> - 1 do {
#    random_direction := uniformly at random choose a direction orthogonal to used_directions;
#    remaining_main_direction := part of main movement direction which is orthogonal to used_directions;
#    normalize both directions;
#    next_direction = random_direction * <reduction> + remaining_main_direction;
#    // The smaller the value of <reduction> is the more of the
#    // remaining_main_direction will be covered by the next direction
#    perform standard PSO velocity update with local/global attractor in this direction;
#    add next_direction to used_directions;
#  } end for;
#  calculate orthogonal part of difference vector to attractors;
#  perform standard PSO velocity update in these directions;
#
# positionAndVelocityUpdater testing
#  The "positionAndVelocityUpdater testing" is just for testing and debugging.
#  Behavior is not defined and may change during the process or after software
#  updates.


# Set the bound handling strategy. The chosen strategy will be applied to
# handle/avoid positions outside the search space (outside the function bounds.
boundhandling noBounds
# boundhandling < noBounds | absorption <adjust dimensions> | randomforth <adjust dimensions> | random resetAll | random resetViolated | hyperbolic | nearest | reflect | torus >
# <adjust dimensions> ::= markAllOnChange | markAllOutsideBoundsWithoutChange | markAllOnBoundsAfterChange
#
# boundhandling noBounds
#  With bound handling "noBounds" it is allowed that the new position is
#  outside of the function bounds. No change of position or velocity happens in
#  that case. In addition to that bound handling strategy with command
#  "functionInfinityOutside" it can be specified whether all values outside of
#  the function bounds are calculated with the specified function or are
#  directly set to +infinity.
#
# boundhandling absorption <adjust dimensions>
#  With bound handling "absorption" the new position will be the old position +
#  velocity if this lies within the bounds and old position + scale * velocity
#  otherwise, where scale is the largest value in [0.0, 1.0] such that the new
#  position lies within or on the function bounds. "<adjust dimensions>"
#  specifies which dimensions are marked as to be adjusted with the velocity
#  adjustment.
#
# boundhandling randomforth <adjust dimensions>
#  With bound handling "randomforth" the new position will be the old position
#  + velocity if this lies within the bounds and old position + randval * scale
#  * velocity otherwise, where randval is a random value in the interval [0, 1]
#  (uniformly at random for each application) and scale is the largest value in
#  [0.0, 1.0] such that the new position lies within or on the function bounds.
#  "<adjust dimensions>" specifies which dimensions are marked as to be
#  adjusted with the velocity adjustment.
#
# boundhandling random resetAll
#  With bound handling "random" the position is resampled uniformly inside the
#  function bounds. With additional option "random resetAll" all dimensions are
#  resampled.
#
# boundhandling random resetViolated
#  With bound handling "random" the position is resampled uniformly inside the
#  function bounds. With additional option "random resetViolated" only for
#  dimensions with violations resampling is applied.
#
# boundhandling hyperbolic
#  With bound handling "hyperbolic" the velocities are adjusted each time. For
#  each particle and for each dimension the following is applied:
#  If velocity is positive then it is multiplied by
#    1 / ( 1 + abs( velocity / ( function upper bound - position ) ) )
#  else it is multiplied by
#    1 / ( 1 + abs( velocity / ( position - function lower bound ) ) )
#  WARNING: Any specification of a velocity adjustment is ignored with
#  hyperbolic, because it already adjusts velocity.
#
# boundhandling nearest
#  With bound handling "nearest" the position is adjusted to the nearest
#  position inside or on the function bounds.
#
# boundhandling reflect
#  With bound handling "reflect" the movement is reflected at the function
#  boundaries (also known as mirror).
#
# boundhandling torus
#  With bound handling "torus" the movement is wrapped around the function
#  bounds. For the movement equations the directions to the attractors are
#  calculated either directly or through the function bounds depending on which
#  of the possible directions is shorter.
#  I. e. let X = 0.8 , L = 0.1 and G = 0.6 be position, local attractor and
#  global attractor in a single dimension and let 0 be the lower function bound
#  and 1 be the upper function bound then the direction to the local attractor
#  "(L-X)" is 0.3 and the direction to the global attractor is -0.2.
#  The bound handling "bounded mirror" can not be stated directly because
#  mirroring a function is not possible with functionality of bound handling.
#  Instead it can be described by the boundhandling torus and manually
#  mirroring the function. Mirroring the function can be easily achieved. Let
#  <function description> be the <function type> which should be processed and
#  let <lb> and <ub> be the lower and upper function bounds. Then you can use
#  the following commands for mirroring:"function reduce functionEvaluation
#  <function description> combine - constant <ub> abs identity" and
#  "functionbounds 0 (<number of dimensions> - 1) (<lb> - <ub>) (<ub> - <lb>)",
#  where expressions in round brackets "(" ")" need to be calculated by hand.
#  With this commands the function is mirrored to the positive direction.  For
#  mirroring to the negative direction you can use
#  "function reduce functionEvaluation <function description> combine + constant <lb> abs identity"
#  and "functionbounds 0 (<number of dimensions> - 1) (<lb> - <ub>) (<ub> - <lb>)".

# <adjust dimensions>
#  "<adjust dimensions>" specifies which dimensions are marked as to be
#  adjusted with the velocity adjustment.
#
# <adjust dimensions> = markAllOnChange
#  "markAllOnChange" specifies that all dimensions are marked if any scaling is
#  necessary.
#
# <adjust dimensions> = markAllOutsideBoundsWithoutChange
#  "markAllOutsideBoundsWithoutChange" specifies that all dimensions are marked
#  where the new position would have been outside of the bounds without scaling.
#
# <adjust dimensions> = markAllOnBoundsAfterChange
#  "markAllOnBoundsAfterChange" specifies that all dimensions are marked where
#  the scaled new position lies on the boundary.

# This command decides how the function value is set if the position is outside
# of the function bounds.
functionBehaviorOutsideOfBounds infinity
#functionBehaviorOutsideOfBounds < normal | infinity | periodic >
#
# functionBehaviorOutsideOfBounds normal
#  The option "normal" tries to evaluate the function with specified evaluation
#  even if the position is outside of the function bounds.
#
# functionBehaviorOutsideOfBounds infinity
#  The option "infinity" sets the value to +infinity if the objective function
#  is evaluated on positions outside of the function bounds.
#
# functionBehaviorOutsideOfBounds periodic
#  If the position is outside of the function bounds then the option "periodic"
#  moves the position with stepsize according to the distance from lower to
#  upper function bound inside the search space and then evaluates the
#  function.
#  I.e. Let LB UB and X be lower function bound, upper function bound and
#  position in current dimension. Then the evaluated position is
#  (X - floor((X - LB) / (UB - LB)) * (UB - LB)).
#  This is applied to all dimensions, where the position is outside of the
#  function bounds.


# Set the strategy how the velocity is adjusted if the respective dimension is
# marked by the bound handling strategy.
velocityAdjustment none
#velocityAdjustment < none | zero | mirror | deterministicBack <lambda> | randomBack | adjust >
#
# The respective velocity adjustment is applied after the bound handling
# strategy and it is applied to all dimensions which are marked by the bound
# handling strategy as adjusted.
#
# velocityAdjustment none
#  Velocity will not be adjusted.
#
# velocityAdjustment zero
#  Velocity of adjusted dimensions will be set to zero.
#
# velocityAdjustment mirror
#  Velocity of adjusted dimensions will be multiplied by -1.
#
# velocityAdjustment deterministicBack <lambda>
#  Velocity of adjusted dimensions will be multiplied by -<lambda>. <lambda>
#  should be a floating point value. The value is most likely positive.
#  A typical value for <lambda> is 0.5.
#
# velocityAdjustment randomBack
#  Same as deterministicBack but <lambda> is sampled independent and uniformly
#  at random in [0,1].
#
# velocityAdjustment adjust
#  The new velocity is adjusted to the difference of the new position, which is
#  already modified by a bound handling mechanism, and the old position.

# Set when the global attractor is updated.
updateGlobalAttractor eachParticle
#updateGlobalAttractor < eachIteration | eachParticle >
#
# updateGlobalAttractor eachIteration
#  The option "eachIteration" means that the global attractor is updated after
#  each iteration. Particles with higher index do not recognize improvements of
#  earlier particles in the same iteration.
#
# updateGlobalAttractor  eachParticle
#  The option "eachParticle" means that the global attractor is updated
#  immediately after each particle has found a new position.

#Specify the random number generator (RNG) which should be used. Specifying
#only the seed uses the standard linear congruence random number generator.
srand 42
#srand <rng description>
#<rng description>             ::= <seed> | linearCongruenceRNG <seed> <lcrng>
#<lcrng>                       ::= standard <floating point generation 1> |
#                                  mod2p63 <multiplier> <adder> <floating point generation 1> |
#                                  specific <multiplier> <adder> <modulus> <floating point generation 2>
#<floating point generation 1> ::= fast | intense <used bits>
#<floating point generation 2> ::= fast | intense
#<seed>                        ::= <nonnegative integer value>
#<multiplier>                  ::= <nonnegative integer value>
#<adder>                       ::= <nonnegative integer value>
#<modulus>                     ::= <positive integer value>
#<used bits>                   ::= <positive integer value>

# A linear congruence RNG works in the following way:
# It contains a <multiplier> (a nonnegative integer less than 2^63), an adder
# (a nonnegative integer less than 2^63) and a <modulus> (a positive integer
# less or equal than 2^63).

# <rng description> = <seed>
#  This option uses a standard linear congruence RNG with multiplier
#  1571204578482947281, additive term 12345678901234567 and modulus
#  9223372036854775808.
#
# <rng description> = linearCongruenceRNG <seed> <lcrng>
#  This option uses a linear congruence RNG with variable multiplier, additive
#  term and modulus.

# <lcrng> = standard <floating point generation 1>
#  This option uses a standard linear congruence RNG with multiplier
#  1571204578482947281, additive term 12345678901234567 and modulus
#  9223372036854775808.
#
# <lcrng> = mod2p63 <multiplier> <adder> <floating point generation 1>
#  This option uses a standard linear congruence RNG with modulus
#  9223372036854775808=2^{63} and variable multiplier and additive term.
#
# <lcrng> = specific <multiplier> <adder> <modulus> <floating point generation 2>
#  This option uses a standard linear congruence RNG with variable multiplier,
#  additive term and modulus.

# <floating point generation 1> = fast
#  If floating point generation is specified as fast then for floating point
#  value generation a random double value is converted to a highly precise
#  floating point value.
#
# <floating point generation 1> = intense <used bits>
#  If floating point generation is specified as intense then the result is
#  sum_{i=1..t} (highest <used bits> bits of a random integer value) / ( 2^( i * <used bits> ) ),
#  where t is as large such that all bits of the random highly precise floating
#  point value are randomly generated.

# <floating point generation 2> = fast
#  If floating point generation is specified as fast then for floating point
#  value generation a random double value is converted to a highly precise
#  floating point value.
#
# <floating point generation 2> = intense
#  If floating point generation is specified as intense then the result is
#  sum_{i=1..t} (random 64 bit integer value) / (<modulus>^i), where t is as
#  large such that all bits of the random highly precise floating point value
#  are randomly generated.

# <seed> is the seed of the RNG. This number should be a non negative integer.
# RNGs have 3 methods for random number generation. (Generation of random long long values, double values and mpf_t values)
# The next random long long value is calculated with the formula
#  (<adder> + <seed> * <multiplier>) mod <modulus>
#  where <seed> is either the specified <seed> if the method is called the first time or the previously generated random number.
# The next random double value is calculated by a random long long value divided by the <modulus>.
# If mpf generation is specified as fast then for mpf_t value generation a random double value is converted to a mpf_t value.
# If mpf generation is specified as intense then the result is sum_{i=1..t} (random long long value) / (<modulus>^i)
# where t is as large such that all bits of the random mpf_t are randomly generated.
# If additionally the <used bits> can be specified then only the highest <used bits> bits of the random long long value are used.
# This makes sense because if the modulus is a power of 2 then the lowest bits have very short periodicity.
# The formula then changes to sum_{i=1..t} (random integer value of the highest <used bits> bits) / ( 2^( i * <used bits> ) ).
# With subcommand specific all values can be specified. For example
#srand linearCongruenceRNG 1 specific 2 3 4 fast
#srand linearCongruenceRNG 1 specific 2 3 4 intense
# With subcommand mod2p63 the <modulus> is fixed to the value 2^63.
# This is much faster because modulo combinations are mainly implicitly done by overflows of unsigned long long values.
# Examples:
#srand linearCongruenceRNG 1 mod2p63 2 3 fast
#srand linearCongruenceRNG 1 mod2p63 2 3 intense 30
# With subcommand standard also the <multiplier> and <adder> are fixed. (<multiplier> = 1571204578482947281, <adder> = 12345678901234567).
# Examples:
#srand linearCongruenceRNG 1 standard fast
#srand linearCongruenceRNG 1 standard intense 30
# The following four definitions produce the same random values:
#srand 42
#srand linearCongruenceRNG 42 standard fast
#srand linearCongruenceRNG 42 mod2p63 1571204578482947281 12345678901234567 fast
#srand linearCongruenceRNG 42 specific 1571204578482947281 12345678901234567 9223372036854775808 fast


##############################################################
########            PRECISION CONFIGURATION           ########
##############################################################

# Set initial precision (in bits) of the used floating point data type
# (Accepted values are positive integers).
initialprecision 500
# Set precision (in bits) of the used floating point data type (Accepted values
# are positive integers). According to this value checks are performed to
# ensure that calculations are reliable even if less bits (according to the
# specified number here) are used. If this is not the case then the precision
# will be increased.
precision 500


# Set when the precision is checked.
checkprecision allExceptStatistics
#checkprecision < all | allExceptStatistics | never >

# checkprecision all
#  With this option precision checks are performed always.
#
# checkprecision allExceptStatistics
#  With this option precision checks are performed always except on statistical
#  calculations. This is useful if runs should be reproducible not depending on
#  whether statistics are done or not.
#
# checkprecision never
#  With this option precision checks are performed never.


# Set the ratio how often the precision is checked expectedly (respecting the
# choice fo "checkprecision" command).
checkprecisionprobability 1.0
#checkprecisionprobability <floating point number>
#
# A ratio of 0.0 means that the precision is never checked. A ratio of 1.0
# means that the precision is always checked if it is triggered by
# "checkprecision" option.  A ratio of 0.5 means that for 50% of the
# calculations the precision is checked if it is triggered by "checkprecision"
# option.

# Set the precision (in digits) of numbers in the produced output (in general
# for all floating point numbers in statistical files). If the output precision
# is set to -1 then the full precision of the internal floating point values
# are displayed.
outputPrecision 10
#outputPrecision < <output precision in digits> | -1 >

# <output precision in digits> ::= <positive integer value>


##############################################################
########         SPECIFICATION WHICH STATISTICS       ########
########           ARE WRITTEN TO DATA FILES          ########
##############################################################

#showStatistics <start step> <end step> <steps between shows>
# Set at which iterations the statistics should be stored. If more such times
# are specified all will be regarded. Statistics will be stored for all
# iterations t such that <start step> <= t <= <end step> and t = <start step> +
# i * <interval> for some integer i.
# For example: The commands "showStatistics 100 1222111222 100" and
# "showStatistics 10000 10100 1" together will show statistics each 100 steps
# (for a very long period) AND each step between 10000 and 10100.


#showStatistic <statistic type>
#showNamedStatistic <statistic name> <statistic type>
# This commands can specify statistics that can be stored to analyze the PSO.
# Examples are the position of particles, function values and many more.
# Additionally for "showNamedStatistic" a name of this statistic can be defined.
# This name has to be unique and can contain characters A-Z, a-z and 0-9. The
# name is used as suffix for the file containing the data of this statistic.
#
# The type of statistic (<statistic type>) should be specified
# as described with the following grammar, which is described
# in Backus-Naur Form:
#
#
# <statistic type>                 ::= <direct statistic type> | <operation> <statistic type> |
#                                      <reduce operator> <specific statistic type> |
#                                      combine <combination> <statistic type> <statistic type>
# <direct statistic type>          ::= globalBestPosition | globalBestPositionDistanceTo1DOptimum |
#                                      globalBestPositionFunctionEvaluation | localAttractorUpdates |
#                                      globalAttractorUpdates | precision |
#                                      constant <dimensions> <constant value>
# <specific statistic type>        ::= <direct specific statistic type> |
#                                      <operation> <specific statistic type> |
#                                      combine <combination> <specific statistic type> <specific statistic type>
# <direct specific statistic type> ::= position | velocity | localAttractor | globalAttractor |
#                                      functionDifference | absVelocityPlusDistToGlobalAttractor <scale> |
#                                      sqrtAbsVelocityPlusSqrtDistToGlobalAttractor <scale> |
#                                      constant <constant value> | deltaUpdateCounters
# <constant value>                 ::= E | Pi | plusInfinity | minusInfinity | <floating point number>
# <operation>                      ::= sqrt | log2 | logE | abs | pow <float exponent> | exp |
#                                      sin | cos | tan | arcsin | arccos | arctan
# <reduce operator>                ::= reduce particle <reduce type> | reduce dimension <reduce type>
# <reduce type>                    ::= specific <element id> | increasingOrderNthObject <element id> |
#                                      arithmeticAverage | geometricAverage | sum | product | maximum |
#                                      minimum | functionEvaluation <function type> | objectiveFunctionEvaluation
# <combination>                    ::= + | - | * | / | min | max
# <dimensions>                     ::= <positive integer value>
# <float exponent>                 ::= <floating point number>
# <element id>                     ::= <nonnegative integer>
# <scale>                          ::= <floating point number>

# <statistic name>
#  You can specify the name of the statistic, which specifies the final part of
#  the respective filename. Please do not use any whitespace characters.
#  Furthermore only the letters A-Z, a-z and 0-9 are allowed.
#
# <statistic type>
#  A <statistic type> is some specification of an evaluation which can be
#  executed at the specified iterations (specified by command
#  "showStatistics"). In general it produces at each evaluation a list of
#  numbers which is written to the respective statistics file.

# <direct statistic type>
#  A <direct statistic type> describes a specific statistic directly. Examples
#  are the global best position or the objective function value at the global
#  best position.

# <direct statistic type> = globalBestPosition
#  "globalBestPosition" represents the best position found so far by the swarm.
#
# <direct statistic type> = globalBestPositionDistanceTo1DOptimum
#  "globalBestPositionDistanceTo1DOptimum" represents the distance of the
#  global best position to the nearest local optimum if only a single dimension
#  is variable.
#
# <direct statistic type> = globalBestPositionFunctionEvaluation
#  "globalBestPositionFunctionEvaluation" represents the function value of the
#  specified objective function where the input position is the best position
#  found so far.
#
# <direct statistic type> = localAttractorUpdates
#  "localAttractorUpdates" counts for each particle the number of changes of
#  its local attractor since the beginning.
#
# <direct statistic type> = globalAttractorUpdates
#  "globalAttractorUpdates" counts for each particle the number of changes of a
#  global attractor caused by that particle since the beginning.
#
# <direct statistic type> = precision
#  "precision" represents the current precision in bits, which is used for all
#  calculations.
#
# <direct statistic type> = constant <dimensions> <constant value>
#  "constant <dimensions> <constant value>" represents a statistic, which
#  always evaluates to the same specified value. The number of dimensions needs
#  to be specified, because the generated vector needs to have the correct
#  number of entries if it should be combined with other statistics.

# <constant value>
#  "<constant value>" represents an evaluation, which always results in
#  the same specified value.
# <constant value> = E
#  If "<constant value>" is set to "E" then we have Euler's number. It is
#  approximately 2.71828. This value is always evaluated according to the
#  current precision.
# <constant value> = Pi
#  If "<constant value>" is set to "Pi" then we have The number Pi. It is
#  approximately 3.14159. This value is always evaluated according to the
#  current precision.

# <operation> <statistic type>
# <operation> <specific statistic type>
#  An <operation> is applied to the result delivered by the connected
#  <statistic type> object or <specific statistic type>. Examples for
#  operations are the logarithm, the square root or trigonometric functions.
# <operation> = sqrt:
#  "sqrt" is the square root.
#   WARNING: executions with negative values result in undefined values.
# <operation> = log2:
#  "log2" is the logarithm with base 2.
#   WARNING: executions with negative values result in undefined values.
# <operation> = logE:
#  "logE" is the natural logarithm (logarithm with base E).
#   WARNING: executions with negative values result in undefined values.
# <operation> = abs:
#  "abs" is the absolute value.
# <operation> = pow <float exponent>:
#  "pow <float exponent>" is the power of the value with the specified
#  exponent.
#   WARNING: executions with negative values (can) result in undefined values.
# <operation> = exp:
#  "exp" is the exponential function.
# <operation> = sin:
#  "sin" is the sine function.
# <operation> = cos:
#  "cos" is the cosine function.
# <operation> = tan:
#  "tan" is the tangent function.
# <operation> = arcsin:
#  "arcsin" is the respective arcus-functions to the sine function
#  (inverse trigonometric function)
# <operation> = arccos:
#  "arccos" is the respective arcus-functions to the cosine function
#  (inverse trigonometric function)
# <operation> = arctan:
#  "arctan" is the respective arcus-functions to the tangent function
#  (inverse trigonometric function)

# <statistic type> = <reduce operator> <specific statistic type>
#  A <specific statistic type> produces a two-dimensional statistic (There is a
#  value for each particle and dimension - An example would be the position of
#  all particles). The reduce operator reduces the data received for each
#  particle and dimension to some list of numbers. Some kind of aggregation can
#  be applied over the particles or over the dimensions (Examples are the sum
#  or the choice of a specific particle/dimension).

# <reduce operator>
#  The reduce operator reduces the data received for each particle and
#  dimension to some list of numbers. Some kind of aggregation can be applied
#  over the particles or over the dimensions (Examples are the sum or the
#  choice of a specific particle/dimension).
# <reduce operator> = reduce particle <reduce type>
#  "reduce particle <reduce type>" reduces the data over the particles and
#  produces one value for each dimension. (Example: Let the number of particles
#  be 2 and the number of dimensions be 3. Let the position of particle 0 be
#  pos(0)=(1,2,3) and let the position of particle 1 be pos(1)=(5,6,7) then the
#  following statistics can be applied: "reduce particle specific 0 position"
#  produces the data (1,2,3) and "reduce particle specific 1 position" produces
#  the data (5,6,7)).
# <reduce operator> = reduce dimension <reduce type>
#  "reduce dimension <reduce type>" reduces the data over the dimensions and
#  produces one value for each particle. (Example: Let the number of particles
#  be 2 and the number of dimensions be 3. Let the position of particle 0 be
#  pos(0)=(1,2,3) and let the position of particle 1 be pos(1)=(5,6,7) then the
#  following statistics can be applied: "reduce dimension specific 0 position"
#  produces the data (1,5), "reduce dimension specific 1 position" produces the
#  data (2,6) and "reduce dimension specific 2 position" produces the data
#  (3,7)).

# <reduce type>
#  The reduce operator specifies how values are combined.
#
# <reduce type> = specific <element id>
#  "specific <element id>" picks only the value at some specified index. Please
#  note that the indices are 0-indexed.
#   Example:
#    Let the number of particles be 2 and the number of dimensions be 3. Let
#    the position of particle 0 be pos(0)=(1,2,3) and let the position of
#    particle 1 be pos(1)=(5,6,7) then the following statistics can be applied:
#    "reduce particle specific 0 position" produces the data (1,2,3),
#    "reduce particle specific 1 position" produces the data (5,6,7),
#    "reduce dimension specific 0 position" produces the data (1,5),
#    "reduce dimension specific 1 position" produces the data (2,6) and
#    "reduce dimension specific 2 position" produces the data (3,7).
#
# <reduce type> = increasingOrderNthObject <element id>
#  "increasingOrderNthObject <element id>" picks the value at the specified
#  position after the values, which should be reduced, are sorted. Please note
#  that the indices are 0-indexed.
#   Example:
#    Let the number of particles be 2 and the number of dimensions be 3. Let
#    the position of particle 0 be pos(0)=(7,2,9) and let the position of
#    particle 1 be pos(1)=(6,8,1) then the following statistics can be applied:
#    "reduce particle increasingOrderNthObject 0 position" produces the data (6,2,1),
#    "reduce particle increasingOrderNthObject 1 position" produces the data (7,8,9),
#    "reduce dimension increasingOrderNthObject 0 position" produces the data (2,1),
#    "reduce dimension increasingOrderNthObject 1 position" produces the data (7,6) and
#    "reduce dimension increasingOrderNthObject 2 position" produces the data (9,8).
#
# <reduce type> = arithmeticAverage
#  "arithmeticAverage" calculates the arithmetic average of the values which
#  should be reduced.
#   Example:
#    Let the number of particles be 2 and the number of dimensions be 3. Let
#    the position of particle 0 be pos(0)=(2,4,3) and let the position of
#    particle 1 be pos(1)=(6,8,1) then the following statistics can be applied:
#    "reduce particle arithmeticAverage position" produces the data (4,6,2) and
#    "reduce dimension arithmeticAverage position" produces the data (3,5)).
#
# <reduce type> = geometricAverage
#  "geometricAverage" calculates the geometric average of the values which
#  should be reduced.
#   Example:
#    Let the number of particles be 2 and the number of dimensions be 3. Let
#    the position of particle 0 be pos(0)=(64,1,729) and let the position of
#    particle 1 be pos(1)=(256,4,2916) then the following statistics can be
#    applied:
#    "reduce particle geometricAverage position" produces the data (128,2,1458) and
#    "reduce dimension geometricAverage position" produces the data (36,144).
#
# <reduce type> = sum
#  "sum" caculates the sum of the values which should be reduced.
#   Example:
#    Let the number of particles be 2 and the number of dimensions be 3. Let
#    the position of particle 0 be pos(0)=(2,4,3) and let the position of
#    particle 1 be pos(1)=(6,8,1) then the following statistics can be applied:
#    "reduce particle sum position" produces the data (8,12,4) and
#    "reduce dimension sum position" produces the data (9,15).
#
# <reduce type> = product
#  "product" calculates the product of the values which should be reduced.
#
# <reduce type> = maximum
#  "maximum" calculates the maximal value of the values which should be reduced.
#
# <reduce type> = minimum
# "minimum" calculates the minimal value of the values which should be reduced.
#
# <reduce type> = functionEvaluation <function type>
#  "functionEvaluation <function type>" interprets the values which should be
#  reduced as input of the specified function and evaluates this function. This
#  might fail if the number of entries does not match the specified number of
#  dimensions, because then the input can possibly not be interpreted as valid
#  position.
#   <function type> is specified in the section describing functions.
#
# <reduce type> = objectiveFunctionEvaluation
#  "objectiveFunctionEvaluation" interprets the values which should be reduced
#  as input of the specified objective function and evaluates this function.
#  This might fail if the number of entries does not match the specified number
#  of dimensions, because then the input can possibly not be interpreted as
#  valid position.
#  The objective function is specified by the keyword "function".

# <statistic type> = combine <combination> <statistic type> <statistic type>
# <specific statistic type> = combine <combination> <specific statistic type> <specific statistic type>
#  The combine commands
#  "combine <combination> <statistic type> <statistic type>"
#  "combine <combination> <specific statistic type> <specific statistic type>"
#  can be used to evaluate complex statistics. You can use add (+), subtract
#  (-), multiply (*), divide (/), minimum (min) and maximum (max) as possible
#  combinations to combine various statistics. Each combination is executed
#  element wise. The option is described by a prefix notation for the
#  evaluation which uniquely specifies the order of execution.
#   WARNING: Undefined values can not be compared (e.g. for minimum). Undefined
#   values can appear for example if there is a division by zero.

# <specific statistic type>
#  A <specific statistic type> produces a two-dimensional statistic (There is a
#  value for each particle and dimension - An example would be the position of
#  all particles). It needs to be reduced in some way to receive a list of
#  numbers, which can then be displayed in a data file.

# <direct specific statistic type>
#  A "<direct specific statistic type>" describes a specific "<specific
#  statistic type>" directly. Examples are the positions or the velocities of
#  all particles.

# <direct specific statistic type> = position
#  "position" represents the positions for each particle.
#
# <direct specific statistic type> = velocity
#  "velocity" represents the velocities for each particle.
#
# <direct specific statistic type> = localAttractor
#  "localAttractor" represents the local attractor for each particle.
#
# <direct specific statistic type> = globalAttractor
#  "globalAttractor" represents the global attractor for each particle. Please
#  note that they can be different depending on the neighborhood topology.
#
# <direct specific statistic type> = functionDifference
#  "functionDifference" means abs(f(x)-f(x')), where x is the position and
#  x'[dim] = x[dim] + v[dim] for the measured dimension and x'[dim] = x[dim]
#  for all other dimensions, where v is the velocity.
#
# <direct specific statistic type> = absVelocityPlusDistToGlobalAttractor <scale>
#  "absVelocityPlusDistToGlobalAttractor <scale>" means
#  <scale> * abs(v[dim]) + abs(x[dim]-g[dim]), where x is the position, v is
#  the velocity, g is the global attractor and dim is the measured dimension.
#
# <direct specific statistic type> = sqrtAbsVelocityPlusSqrtDistToGlobalAttractor <scale>
#  "sqrtAbsVelocityPlusSqrtDistToGlobalAttractor <scale>" means
#  <scale> * sqrt( abs( v[dim] ) ) + sqrt( abs( x[dim] - g[dim] ) ),
#  where x is the position, v is the velocity, g is the global attractor and
#  dim is the measured dimension.
#
# <direct specific statistic type> = constant <constant value>
#  "constant <constant value>" represents a statistic, which always evaluates
#  to the same specified value. This specific statistic can be combined with
#  other specific statistics. It has a value for each particle and each
#  dimension.
#
# <direct specific statistic type> = deltaUpdateCounters
#  "deltaUpdateCounters" represents a statistic, which counts the number of
#  delta updates for each particle and dimension. For obvious reasons if the
#  position and velocity updater is not a delta updater (delta or deltatcs)
#  then this statistic evaluates to zero.

# Examples:
#showStatistic log2 reduce particle maximum abs position
# This command shows for each dimension the maximal absolute value,
# which any of the particles have in logarithmic scale. This might be helpful
# if the swarm should converge to origin.
#
#showStatistic globalBestPosition
# This displays just the position of the best position found so far.
#
#showStatistic log2 reduce particle arithmeticAverage abs velocity
# This displays the arithmetic averages of the particles absolute velocities in
# logarithmic scale.
#
#showNamedStatistic myStatistic log2 sqrt abs sqrt pow 2 globalBestPosition
# If automatic filename becomes confusing then another filename can be specified.
#
# Further Examples:
#showStatistic log2 abs globalBestPosition
#showStatistic log2 reduce particle maximum abs velocity
#showStatistic log2 globalBestPositionDistanceTo1DOptimum
#showStatistic log2 reduce particle maximum functionDifference
#showStatistic log2 reduce particle maximum absVelocityPlusDistToGlobalAttractor 1.0
#showStatistic log2 sqrt reduce particle sum absVelocityPlusDistToGlobalAttractor 1.0
#showStatistic log2 reduce particle sum sqrtAbsVelocityPlusSqrtDistToGlobalAttractor 1.0
# alternative specification of the previous statistic:
#showStatistic log2 reduce particle sum combine + sqrt abs velocity sqrt abs combine - position globalAttractor


# For debugging and observation of the swarm this option can be used.
#debugswarm
# This command activates the <debugswarm>-mode (generation of pictures which
# visualize the current state of the swarm and further output on terminal). The
# program generates a folder according to the current file prefix. Execute the
# small script in this folder to generate the image files for each visualized
# step. The prefix of the files are the referencing steps.
# WARNING 1:
#  "gnuplot" has to be installed to create pictures by the created script.
# WARNING 2:
#  It might be possible that you can not easily kill the PSO_program task with
#  Ctrl+C in the terminal. You need to kill the process either by your
#  specified runcheck file or by typing "killall PSO_program" in another
#  terminal (this variant kills ALL(!!) instances of PSO_program) or you can
#  use the programs "top" or "htop" to kill the respective process.
# WARNING 3:
#  It might be possible that this option causes large memory usage on hard
#  disk.

#debugswarmShowGlobalAttractorTrajectory <number of footprints>
# This command specifies how many of the recent global best found positions
# will be visualized in the generated images as footprints.
debugswarmShowGlobalAttractorTrajectory 20

#debugswarmImageGenerationFrequency <nonnegative integer value>
# This command specifies how often the image will be generated. If the
# specified value is zero then no images will be generated. If the specified
# value "n" is positive each n-th iteration/step an image will be generated.
debugswarmImageGenerationFrequency 10

#debugswarmShowGlobalAttractor < true | false >
# This command specifies whether the value and position of the current global
# best found position should be displayed on the terminal at each iteration.
debugswarmShowGlobalAttractor true

# The following command specifies the resolution of the generated images.
# Please specify the width (X) and height (Y) of the generated image in pixels.
#debugswarmXresolution <width of generated image in pixels>
debugswarmXresolution 2560
#debugswarmYresolution <height of generated image in pixels>
debugswarmYresolution 1440

#debugswarmGnuplotTerminal <gnuplot terminal>
# This command specifies which terminal should be used in gnuplot. The
# available terminals depend on your system. Usually available are terminals
# such as "svg", "png", "pngcairo" and many more.
debugswarmGnuplotTerminal svg

#debugswarmOutput <image file extension>
# This command specifies the extension of the generated image file. The
# extension should match to the output file generated by the chosen gnuplot
# terminal.
debugswarmOutput svg


##############################################################
########             MISCELLANEOUS OPTIONS            ########
##############################################################

# Set whether the current date and time should be included in the prefix of all
# file names.
includeSystemTimeInFilename true
#includeSystemTimeInFilename < true | false >
#
# WARNING: There is no check whether the respective prefix is already in use.
# If a prefix is used repeatedly in the same folder, then the program may
# produce wrong / useless data and may also destroy data of other executions of
# this program. Therefore it is highly recommended to set the
# "includeSystemTimeInFilename" value to true in such cases, because this
# automatically produces different prefixes for each execution, which has not
# started at the same second.

#fileprefix <alphanumeric value>
# Set file prefixes of generated data. If none is specified then an automatic
# string is generated by specified values in this configuration file. Only
# alphanumeric characters are allowed here.
# Example:
#fileprefix testrun001

#runcheck guideline_configuration_files/runcheck.conf
#runcheck <runcheck configuration file>
# Set the file name for configuration file which specifies when / whether the
# program is allowed to run. The program parses this file repeatedly. Therefore
# changes are recognized on runtime. If the program recognizes that it is not
# allowed to run then it stores its current data and terminates normally
# ensuring that no data loss appears. This can be used to terminate current PSO
# runs and restart them later. See sample file runcheck.conf for available
# possibilities. Allowed characters are 0-9, a-z, A-Z and the four characters
# "./_-". Please note that this command is optional.


#preservebackup <iteration index>
# Set special iteration index/step, where a backup of the PSO should be
# preserved. For example use "preservebackup 0" to receive the backup directly
# after initialization.
